{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegressor: a simplt custom built class implementation for the perceptron logic.\n",
    "\n",
    "src.shared imports: \\\n",
    "numpy as np \\\n",
    "pandas as pd \\\n",
    "matplotlib.pyplot as plt \\\n",
    "utils like load_dataset, calculating metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0ju2GLoDdGNL"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = str(Path.cwd().parents[1])\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.regression.logistic import LogisticRegressor\n",
    "from src.shared import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose a simple dataset suitable for probability calculation. \\\n",
    "The Floods dataset fits these criteria well and is perfect for demonstrating the logistic regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "HuyCMG0rqCsv",
    "outputId": "967f074d-566f-454e-963f-eb029520efaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A table of features correlations with flood probability:\n",
      "DeterioratingInfrastructure        0.229444\n",
      "TopographyDrainage                 0.229414\n",
      "RiverManagement                    0.228917\n",
      "Watersheds                         0.228152\n",
      "DamsQuality                        0.227467\n",
      "PopulationScore                    0.226928\n",
      "Siltation                          0.226544\n",
      "IneffectiveDisasterPreparedness    0.225126\n",
      "PoliticalFactors                   0.225009\n",
      "MonsoonIntensity                   0.224081\n",
      "WetlandLoss                        0.223732\n",
      "InadequatePlanning                 0.223329\n",
      "Landslides                         0.222991\n",
      "AgriculturalPractices              0.221846\n",
      "ClimateChange                      0.220986\n",
      "Urbanization                       0.220867\n",
      "Deforestation                      0.220237\n",
      "Encroachments                      0.218259\n",
      "DrainageSystems                    0.217895\n",
      "CoastalVulnerability               0.215187\n",
      "Name: FloodProbability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "df = load_dataset('floods')\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning ---\n",
    "# There is no need to clean the data as it is already clean in this dataset.\n",
    "\n",
    "\n",
    "# --- 3. Analysis ---\n",
    "# Correlation Matrix (Simple 1-to-1 relationship)\n",
    "correlations = df.corr()['FloodProbability'].sort_values(ascending=False).drop('FloodProbability')\n",
    "print(\"A table of features correlations with flood probability:\")\n",
    "print(correlations)\n",
    "\n",
    "# We can see there is no particular feature that has a very high correlation with flood probability. \n",
    "# This means we will need to use as much features as we can to predict flood probability with the most accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5jkTd1eEkPf",
    "outputId": "add087ba-7b4b-4370-8732-24eb068c8dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40000 samples\n",
      "Mean Absolute Error: 0.0002\n",
      "R-squared Score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Select Features & Target ---\n",
    "# using all features for prediction (we sadly can't plot a 2D or 3D graph because of this)\n",
    "X = df.drop('FloodProbability', axis=1).values\n",
    "y = df['FloodProbability'].values\n",
    "\n",
    "\n",
    "# --- 2. Split Data for training & testing ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "\n",
    "# Normalize features to 0-1 range for better performance\n",
    "train_min = X_train.min(axis=0)\n",
    "train_range = X_train.max(axis=0) - train_min + 1e-15\n",
    "\n",
    "X_train = (X_train - train_min) / train_range\n",
    "X_test = (X_test - train_min) / train_range\n",
    "\n",
    "\n",
    "# --- 3. Training ---\n",
    "print(f\"Training on {len(X_train)} samples\")\n",
    "\n",
    "model = LogisticRegressor()\n",
    "\n",
    "# Small inputs (0-1) yield small gradients, so we use a high Learning Rate for fast convergence.\n",
    "model.fit(X_train, y_train, learning_rate=2, n_epochs=1600, show_progress=False)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mae = calculate_mae(y_test, predictions)\n",
    "r2 = calculate_r2(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
