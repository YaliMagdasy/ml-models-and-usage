{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries\n",
    "\n",
    "NumPy: utilized for high-performance vector arithmetic.\n",
    "\n",
    "Pandas: utilized for dataset management and cleaning.\n",
    "\n",
    "Matplotlib: utilized for generating graphical visualizations.\n",
    "\n",
    "Perceptron: a simplt custom built class implementation for the perceptron logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0ju2GLoDdGNL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path: sys.path.append(module_path)\n",
    "from src.logistic_regressor import LogisticRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the introduction, I chose a simple dataset suitable for probability calculation. \\\n",
    "The Floods dataset fits these criteria well and is perfect for demonstrating the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "HuyCMG0rqCsv",
    "outputId": "967f074d-566f-454e-963f-eb029520efaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A table of features correlations with flood probability:\n",
      "DeterioratingInfrastructure        0.229444\n",
      "TopographyDrainage                 0.229414\n",
      "RiverManagement                    0.228917\n",
      "Watersheds                         0.228152\n",
      "DamsQuality                        0.227467\n",
      "PopulationScore                    0.226928\n",
      "Siltation                          0.226544\n",
      "IneffectiveDisasterPreparedness    0.225126\n",
      "PoliticalFactors                   0.225009\n",
      "MonsoonIntensity                   0.224081\n",
      "WetlandLoss                        0.223732\n",
      "InadequatePlanning                 0.223329\n",
      "Landslides                         0.222991\n",
      "AgriculturalPractices              0.221846\n",
      "ClimateChange                      0.220986\n",
      "Urbanization                       0.220867\n",
      "Deforestation                      0.220237\n",
      "Encroachments                      0.218259\n",
      "DrainageSystems                    0.217895\n",
      "CoastalVulnerability               0.215187\n",
      "Name: FloodProbability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "FILE_PATH = '../datasets/floods.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at {FILE_PATH} was not found.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning ---\n",
    "# There is no need to clean the data as it is already clean in this dataset.\n",
    "\n",
    "\n",
    "# --- 3. Analysis ---\n",
    "# Correlation Matrix (Simple 1-to-1 relationship)\n",
    "correlations = df.corr()['FloodProbability'].sort_values(ascending=False).drop('FloodProbability')\n",
    "print(\"A table of features correlations with flood probability:\")\n",
    "print(correlations)\n",
    "\n",
    "# We can see there is no particular feature that has a very high correlation with flood probability. \n",
    "# This means we will need to use muas much features as we can to predict flood probability with the most accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5jkTd1eEkPf",
    "outputId": "add087ba-7b4b-4370-8732-24eb068c8dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0002\n",
      "R-squared Score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('FloodProbability', axis=1).values\n",
    "y = df['FloodProbability'].values\n",
    "\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "np.random.seed(10)\n",
    "indices = np.random.permutation(len(X))\n",
    "split = int(len(X) * 0.8)\n",
    "\n",
    "X_train, y_train = X[indices[:split]], y[indices[:split]]\n",
    "X_test, y_test = X[indices[split:]], y[indices[split:]]\n",
    "\n",
    "model = LogisticRegressor()\n",
    "model.fit(X_train, y_train, show_progress=False, learning_rate=2, n_epochs=2000)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = np.mean(np.abs(y_pred - y_test))\n",
    "r2 = 1 - (np.sum((y_test - y_pred)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
